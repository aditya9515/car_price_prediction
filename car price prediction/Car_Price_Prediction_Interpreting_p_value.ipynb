{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cN_oEsXfM_LV"
      },
      "source": [
        "# Lesson 69: Car Price Prediction - Interpreting p-value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFjOAv8nAhzQ"
      },
      "source": [
        "### Teacher-Student Activities\n",
        "\n",
        "In the previous class, you learned feature encoding using the one-hot encoding and dummy coding processes. You also learned to calculate the adjusted R-squared value to evaluate a linear regression model.\n",
        "\n",
        "In this class, you will learn the concept of p-value which will help you to determine which features are significant to the dataset and which are not so that you can create your model with those features which are significantly contributing in prediction.\n",
        "\n",
        "Let's quickly run the codes covered in the previous classes and begin this session from **Activity 1: Understanding Hypothesis Testing** section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rqO31eQB5O-"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-uhY3ryaj4N"
      },
      "source": [
        "### Problem Statement\n",
        "\n",
        "Build a linear regression model to predict prices of cars based on its technical specifications such as car manufacturer, its engine capacity, fuel efficiency, body-type etc.\n",
        "\n",
        "**Dataset Description:**\n",
        "\n",
        "The dataset contains 205 rows and 26 columns. Each column represents an attribute of a car as described in the table below.\n",
        "\n",
        "|Sr No.|Attribute|Attribute Information|\n",
        "|-|-|-|\n",
        "|1|Car_ID|Unique id of each car (Interger)|\n",
        "|2|Symboling|Assigned insurance risk rating; a value of +3 indicates that the car is risky; -3 suggests that it is probably a safe car (Categorical)|\n",
        "|3|carCompany|Name of car company (Categorical)|\n",
        "|4|fueltype| fuel-type i.e. petrol or diesel (Categorical)|\n",
        "|5|aspiration|Aspiration used in a car (Categorical)|\n",
        "|6|doornumber|Number of doors in a car (Categorical)|\n",
        "|7|carbody|Body-type of a car (Categorical)|\n",
        "|8|drivewheel|Type of drive wheel (Categorical)|\n",
        "|9|enginelocation|Location of car engine (Categorical)|\n",
        "|10|wheelbase|Weelbase of car (Numeric)|\n",
        "|11|carlength|Length of car (Numeric)|\n",
        "|12|carwidth|Width of car (Numeric)|\n",
        "|13|carheight|Height of car (Numeric)|\n",
        "|14|curbweight|The weight of a car without occupants or baggage (Numeric)|\n",
        "|15|enginetype|Type of engine (Categorical)|\n",
        "|16|cylindernumber|Number of cylinders placed in the car engine (Categorical)||17|enginesize|Capacity of an engine (Numeric)|\n",
        "|18|fuelsystem|Fuel system of a car (Categorical)|\n",
        "|19|boreratio|Bore ratio of car (Numeric)|\n",
        "|20|stroke|Stroke or volume inside the engine (Numeric)|\n",
        "|21|compressionratio|Compression ratio of an engine (Numeric)|\n",
        "|22|horsepower|Power output of an engine (Numeric)|\n",
        "|23|peakrpm|Peak revolutions per minute (Numeric)|\n",
        "|24|citympg|Mileage in city (Numeric)|\n",
        "|25|highwaympg|Mileage on highway (Numeric)|\n",
        "|26|price(Dependent variable)|Price of a car (Numeric)|\n",
        "\n",
        "This data set consists of three types of entities:\n",
        "\n",
        "- the specification of an auto in terms of various characteristics,\n",
        "\n",
        "- its assigned insurance risk rating,\n",
        "\n",
        "- its normalised losses in use as compared to other cars.\n",
        "\n",
        "The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by moving it up (or down) the scale. Actuarians call this process **symboling**. A value of $+3$ indicates that the auto is risky, $-3$ that it is probably pretty safe.\n",
        "\n",
        "The third factor is the relative average loss payment per insured vehicle year. This value is normalized for all autos within a particular size classification (two-door small, station wagons, sports/speciality etc.), and represents the average loss per car per year.\n",
        "\n",
        "**Note:** Several of the attributes in the database could be used as a \"class\" attribute.\n",
        "\n",
        "**Dataset source:** https://archive.ics.uci.edu/ml/datasets/Automobile\n",
        "\n",
        "\n",
        "The above dataset consists of data taken from 1985 Ward's Automotive Yearbook. Here's the list of original sources of the data:\n",
        "\n",
        "1. 1985 Model Import Car and Truck Specifications, 1985 Ward's Automotive Yearbook.\n",
        "\n",
        "2. Personal Auto Manuals, Insurance Services Office, 160 Water Street, New York, NY 10038\n",
        "\n",
        "3. Insurance Collision Report, Insurance Institute for Highway Safety, Watergate 600, Washington, DC 20037\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZEA9P6hDG28"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keVeYBHNDHh8"
      },
      "source": [
        "#### Recap\n",
        "\n",
        "https://student-datasets-bucket.s3.ap-south-1.amazonaws.com/whitehat-ds-datasets/car-prices.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f2emlnJM56A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e7f53f7-6208-4d54-ad7d-eabdb65f4c99"
      },
      "source": [
        "# Import the modules, read the dataset and create a Pandas DataFrame.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Read the dataset\n",
        "cars_df = pd.read_csv(\"https://s3-student-datasets-bucket.whjr.online/whitehat-ds-datasets/car-prices.csv\")\n",
        "\n",
        "# Data Cleaning\n",
        "# Extract the name of the manufactures from the car names and display the first 25 cars to verify whether names are extracted successfully.\n",
        "car_companies = pd.Series([car.split(\" \")[0] for car in cars_df['CarName']], index = cars_df.index)\n",
        "\n",
        "# Create a new column named 'car_company'. It should store the company names of a the cars.\n",
        "cars_df['car_company'] = car_companies\n",
        "\n",
        "# Replace the misspelled 'car_company' names with their correct names.\n",
        "# volkswagen\n",
        "cars_df.loc[(cars_df['car_company'] == \"vw\") | (cars_df['car_company'] == \"vokswagen\"), 'car_company'] = 'volkswagen'\n",
        "\n",
        "# porsche\n",
        "cars_df.loc[cars_df['car_company'] == \"porcshce\", 'car_company'] = 'porsche'\n",
        "\n",
        "# toyota\n",
        "cars_df.loc[cars_df['car_company'] == \"toyouta\", 'car_company'] = 'toyota'\n",
        "\n",
        "# nissan\n",
        "cars_df.loc[cars_df['car_company'] == \"Nissan\", 'car_company'] = 'nissan'\n",
        "\n",
        "# mazda\n",
        "cars_df.loc[cars_df['car_company'] == \"maxda\", 'car_company'] = 'mazda'\n",
        "\n",
        "# Drop 'CarName' column from the 'cars_df' DataFrame.\n",
        "cars_df.drop(columns= ['CarName'], axis = 1, inplace = True)\n",
        "\n",
        "# Data Preparation\n",
        "# Extract all the numeric (float and int type) columns from the dataset.\n",
        "cars_numeric_df = cars_df.select_dtypes(include = ['int64', 'float64'])\n",
        "\n",
        "# Drop the 'car_ID' column from the 'cars_numeric_df' DataFrame.\n",
        "cars_numeric_df.drop(columns = ['car_ID'], axis = 1, inplace = True)\n",
        "\n",
        "# Mapping Categorical Values\n",
        "# Map the values of the 'doornumber' and 'cylindernumber' columns to their corresponding numeric values.\n",
        "words_dict = {\"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5, \"six\": 6, \"eight\": 8, \"twelve\": 12}\n",
        "def num_map(series):\n",
        "    return series.map(words_dict)\n",
        "\n",
        "# Applying the function to the two columns\n",
        "cars_df[['cylindernumber', 'doornumber']] = cars_df[['cylindernumber', 'doornumber']].apply(num_map, axis = 1)\n",
        "\n",
        "# Feature Encoding\n",
        "# Create dummy variables for the 'carbody' columns.\n",
        "car_body_dummies = pd.get_dummies(cars_df['carbody'], dtype = int)\n",
        "\n",
        "# Create dummy variables for the 'carbody' columns with 1 column less.\n",
        "car_body_new_dummies = pd.get_dummies(cars_df['carbody'], drop_first = True, dtype = int)\n",
        "\n",
        "# Create a DataFrame containing all the non-numeric type features.\n",
        "cars_categorical_df = cars_df.select_dtypes(include = ['object'])\n",
        "\n",
        "# Get dummy variables for all the categorical type columns using the dummy coding process.\n",
        "cars_dummies_df = pd.get_dummies(cars_categorical_df, drop_first = True, dtype = int)\n",
        "\n",
        "# Drop the categorical type columns from the 'cars_df' DataFrame.\n",
        "cars_df.drop(list(cars_categorical_df.columns), axis = 1, inplace = True)\n",
        "\n",
        "# Concatenate the 'cars_df' and 'cars_dummies_df' DataFrames.\n",
        "cars_df = pd.concat([cars_df, cars_dummies_df], axis = 1)\n",
        "\n",
        "# Drop the 'car_ID' column\n",
        "cars_df.drop('car_ID', axis = 1, inplace = True)\n",
        "\n",
        "# Test-Train Split\n",
        "# Split the 'cars_df' Dataframe into the train and test sets.\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(cars_df, test_size = 0.3, random_state = 42)\n",
        "\n",
        "# Create separate data-frames for the feature and target variables for both the train and test sets.\n",
        "features = list(cars_df.columns)\n",
        "features.remove('price')\n",
        "\n",
        "X_train = train_df[features]\n",
        "y_train = train_df['price']\n",
        "X_test = test_df[features]\n",
        "y_test = test_df['price']\n",
        "\n",
        "# Feature Scaling\n",
        "# Normalise only the numeric columns that were you had prior to any data-cleaning exercise.\n",
        "def standard_norm(series):\n",
        "  new_series = (series - series.mean()) / series.std()\n",
        "  return new_series\n",
        "\n",
        "# Normalising the features in the train and test sets.\n",
        "X_train[X_train.columns[:16]] = X_train[X_train.columns[:16]].apply(standard_norm, axis = 0)\n",
        "X_test[X_train.columns[:16]] = X_test[X_train.columns[:16]].apply(standard_norm, axis = 0)\n",
        "\n",
        "# Model Building\n",
        "# Build a linear regression model using all the features to predict car prices.\n",
        "import statsmodels.api as sm\n",
        "\n",
        "X_train_sm = sm.add_constant(X_train)\n",
        "lin_reg = sm.OLS(y_train, X_train_sm).fit()\n",
        "\n",
        "# Print the summary of the linear regression report.\n",
        "print(lin_reg.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                  price   R-squared:                       0.977\n",
            "Model:                            OLS   Adj. R-squared:                  0.963\n",
            "Method:                 Least Squares   F-statistic:                     67.51\n",
            "Date:                Fri, 14 Jul 2023   Prob (F-statistic):           3.52e-53\n",
            "Time:                        11:12:50   Log-Likelihood:                -1214.5\n",
            "No. Observations:                 143   AIC:                             2541.\n",
            "Df Residuals:                      87   BIC:                             2707.\n",
            "Df Model:                          55                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==========================================================================================\n",
            "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------------\n",
            "const                   1.111e+04   2193.733      5.066      0.000    6752.981    1.55e+04\n",
            "symboling               -259.2601    338.261     -0.766      0.445    -931.591     413.071\n",
            "doornumber               256.3005    276.490      0.927      0.357    -293.252     805.853\n",
            "wheelbase                462.1973    669.416      0.690      0.492    -868.339    1792.734\n",
            "carlength               -627.4075    676.243     -0.928      0.356   -1971.514     716.699\n",
            "carwidth                1488.5498    503.255      2.958      0.004     488.276    2488.824\n",
            "carheight               -330.0812    362.153     -0.911      0.365   -1049.900     389.738\n",
            "curbweight              2138.0076    870.269      2.457      0.016     408.253    3867.762\n",
            "cylindernumber          -847.8692    723.186     -1.172      0.244   -2285.280     589.542\n",
            "enginesize              4083.0225   1082.968      3.770      0.000    1930.507    6235.538\n",
            "boreratio              -1027.6732    378.099     -2.718      0.008   -1779.186    -276.160\n",
            "stroke                   -75.9375    283.049     -0.268      0.789    -638.529     486.654\n",
            "compressionratio         465.2682   1681.273      0.277      0.783   -2876.444    3806.980\n",
            "horsepower               256.2853    832.526      0.308      0.759   -1398.450    1911.020\n",
            "peakrpm                  831.7857    326.495      2.548      0.013     182.842    1480.729\n",
            "citympg                  639.1211    853.572      0.749      0.456   -1057.446    2335.688\n",
            "highwaympg              -239.9637    769.123     -0.312      0.756   -1768.679    1288.752\n",
            "fueltype_gas            6290.6800   2516.294      2.500      0.014    1289.273    1.13e+04\n",
            "aspiration_turbo        2528.1790    820.112      3.083      0.003     898.118    4158.240\n",
            "carbody_hardtop         -233.7527   1674.144     -0.140      0.889   -3561.296    3093.790\n",
            "carbody_hatchback      -3517.0830   1136.021     -3.096      0.003   -5775.048   -1259.118\n",
            "carbody_sedan          -3523.8275   1243.949     -2.833      0.006   -5996.310   -1051.345\n",
            "carbody_wagon          -4154.1619   1363.304     -3.047      0.003   -6863.876   -1444.448\n",
            "drivewheel_fwd          -850.5823   1150.963     -0.739      0.462   -3138.245    1437.080\n",
            "drivewheel_rwd         -1393.0072   1327.046     -1.050      0.297   -4030.655    1244.640\n",
            "enginelocation_rear     4920.8510   1878.236      2.620      0.010    1187.653    8654.049\n",
            "enginetype_dohcv         290.8615   3118.387      0.093      0.926   -5907.270    6488.993\n",
            "enginetype_l           -1259.1940    958.461     -1.314      0.192   -3164.240     645.852\n",
            "enginetype_ohc          -318.0058    902.080     -0.353      0.725   -2110.988    1474.976\n",
            "enginetype_ohcf         1138.9452   1059.824      1.075      0.286    -967.570    3245.460\n",
            "enginetype_ohcv        -1391.8556   1301.970     -1.069      0.288   -3979.663    1195.952\n",
            "enginetype_rotor        6744.3881   2491.565      2.707      0.008    1792.132    1.17e+04\n",
            "fuelsystem_2bbl         2404.4879   1359.986      1.768      0.081    -298.631    5107.607\n",
            "fuelsystem_4bbl         1132.0482   2592.199      0.437      0.663   -4020.227    6284.324\n",
            "fuelsystem_idi          4822.5828   4052.732      1.190      0.237   -3232.661    1.29e+04\n",
            "fuelsystem_mfi         -2.075e-12   3.21e-12     -0.647      0.519   -8.45e-12     4.3e-12\n",
            "fuelsystem_mpfi         1568.0491   1482.816      1.057      0.293   -1379.208    4515.306\n",
            "fuelsystem_spdi         1158.1552   1718.412      0.674      0.502   -2257.375    4573.685\n",
            "fuelsystem_spfi         2039.4149   2480.546      0.822      0.413   -2890.939    6969.769\n",
            "car_company_audi          14.9686   2053.835      0.007      0.994   -4067.251    4097.188\n",
            "car_company_bmw         7272.2594   1965.043      3.701      0.000    3366.524    1.12e+04\n",
            "car_company_buick       6875.9526   2219.913      3.097      0.003    2463.635    1.13e+04\n",
            "car_company_chevrolet  -4172.9890   2343.759     -1.780      0.078   -8831.465     485.487\n",
            "car_company_dodge      -4140.1906   1782.403     -2.323      0.023   -7682.909    -597.472\n",
            "car_company_honda      -2024.8946   2014.830     -1.005      0.318   -6029.588    1979.799\n",
            "car_company_isuzu      -1568.7948   1939.801     -0.809      0.421   -5424.360    2286.770\n",
            "car_company_jaguar      1491.0493   2560.096      0.582      0.562   -3597.419    6579.517\n",
            "car_company_mazda      -2504.6200   1527.853     -1.639      0.105   -5541.394     532.154\n",
            "car_company_mercury    -1594.0387   2486.135     -0.641      0.523   -6535.502    3347.424\n",
            "car_company_mitsubishi -4572.3670   1771.568     -2.581      0.012   -8093.551   -1051.183\n",
            "car_company_nissan     -3072.2827   1501.862     -2.046      0.044   -6057.396     -87.169\n",
            "car_company_peugeot    -1259.1940    958.461     -1.314      0.192   -3164.240     645.852\n",
            "car_company_plymouth   -4405.8614   1752.695     -2.514      0.014   -7889.532    -922.191\n",
            "car_company_porsche     5532.1130   2496.536      2.216      0.029     569.977    1.05e+04\n",
            "car_company_renault    -3693.7631   2120.914     -1.742      0.085   -7909.309     521.783\n",
            "car_company_saab         809.4785   1941.181      0.417      0.678   -3048.828    4667.785\n",
            "car_company_subaru     -3781.9058   1543.236     -2.451      0.016   -6849.254    -714.558\n",
            "car_company_toyota     -2751.7696   1433.614     -1.919      0.058   -5601.233      97.694\n",
            "car_company_volkswagen -1847.2038   1683.429     -1.097      0.276   -5193.202    1498.794\n",
            "car_company_volvo        237.9138   1973.607      0.121      0.904   -3684.843    4160.671\n",
            "==============================================================================\n",
            "Omnibus:                        1.439   Durbin-Watson:                   1.908\n",
            "Prob(Omnibus):                  0.487   Jarque-Bera (JB):                1.004\n",
            "Skew:                           0.119   Prob(JB):                        0.605\n",
            "Kurtosis:                       3.335   Cond. No.                     1.43e+16\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 5.22e-30. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-85-51939c73ebda>:95: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_train[X_train.columns[:16]] = X_train[X_train.columns[:16]].apply(standard_norm, axis = 0)\n",
            "<ipython-input-85-51939c73ebda>:96: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X_test[X_train.columns[:16]] = X_test[X_train.columns[:16]].apply(standard_norm, axis = 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mebERAD9DtH7"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_cZ9JNVTL10"
      },
      "source": [
        "#### Activity 1: Understanding Hypothesis Testing\n",
        "\n",
        "From the summary report of the linear regression, you may observe that each feature variable has a **p-value** `(P>|t|)` associated with it. The p-value is one of the important statistics which can be used to eliminate features which are not relatively significant in our model. Before understanding the p-value concept, let us first explore the concept of hypothesis testing.\n",
        "\n",
        "**Hypothesis Testing**\n",
        "\n",
        "Hypothesis Testing is basically testing an assumption that we make about a parameter. This assumption may or may not be true. Eg., \"students having an affluent background are more likely to do well in academics in higher education\" is one such hypothesis.\n",
        "\n",
        "The steps followed in hypothesis testing are:\n",
        "\n",
        "1. An initial assumption or hypothesis is made.\n",
        "2. The validity of that hypothesis is tested.\n",
        "3. If the hypothesis is found to be true, it is accepted otherwise it is rejected.\n",
        "\n",
        "There are two types of hypothesis:\n",
        "\n",
        "1. **Null hypothesis:** denoted by $H_0$, is a general statement or an initial assumption which we make about a parameter.\n",
        "2. **Alternative hypothesis:** denoted by $H_1$ or $H_a$, It is contrary to the null hypothesis. It is the hypothesis we would accept if our null hypothesis is found to be false.\n",
        "\n",
        "In hypothesis testing, we need to gather enough evidence to either accept or reject our null hypothesis. There are two types of hypothesis tests that can be used for multiple linear regression:\n",
        "- **F-test:** This test measures the overall significance of all the coefficients.\n",
        "- **T-test:** This test measures the significance of each individual coefficient.\n",
        "\n",
        "Let us first determine the overall significance of our model using the F-test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVqKWc0FWd_K"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtfCyEXmWqZd"
      },
      "source": [
        "#### Activity 2: F-Test\n",
        "\n",
        "The F-test is used to assess all the coefficients collectively. It validates whether any of the independent variables are significant. Let us apply F-test to the car price prediction model.\n",
        "\n",
        "The regression equation for the car price prediction model can be given as\n",
        "\n",
        "$$Y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\dots + \\beta_{59} x_{59} + \\epsilon$$\n",
        "\n",
        "where,\n",
        "\n",
        " - $x_1$ is `symboling`\n",
        " - $x_2$ is `doornumber`\n",
        " - $x_3$ is `wheelbase`\n",
        "\n",
        " $\\vdots$   \n",
        "\n",
        " - $x_{59}$ is `wheelbase` and\n",
        " - $Y$ is the `price`\n",
        "\n",
        "\n",
        "**Step 1: Define null and alternative hypothesis**\n",
        "\n",
        "$H_0: \\beta_1 = \\beta_2 = \\dots = \\beta_{59} = 0$ i.e. all the regression coefficients are equal to zero.\n",
        "\n",
        "$H_1: \\beta_i \\neq 0$, i.e. at least one of the coefficient is not zero.\n",
        "\n",
        "- $H_0$ means that none of the feature or independent variables have a significant relationship with our target variable `price` and our model has no predictive capability.\n",
        "\n",
        "- $H_1$ means that at least one feature variable has a significant relationship with our target variable `price`.\n",
        "\n",
        "**Step 2: Calculate the test statistic value** (in case of F-test it is F-statistic value)\n",
        "\n",
        "It is calculated as\n",
        "\n",
        "$$F* = \\frac{\\textrm{explained variance}}{\\textrm{unexplained variance}} = \\frac{\\text{MSM}}{\\text{MSE}}$$\n",
        "\n",
        "where,\n",
        "\n",
        "- MSM is the Mean of Squares for Model\n",
        "- MSE is Mean of Squared Errors (or Residuals)\n",
        "\n",
        "Further, MSM  is calculated as\n",
        "\n",
        "$$\\text{MSM} = \\frac{\\text{SSM}}{\\text{DFM}}=\\frac{\\sum(y_{\\text{pred}} - \\bar{y})^2}{ p - 1}$$\n",
        "\n",
        "where,\n",
        "- SSM is the Sum of Squares for Model\n",
        "- DFM is Degrees of Freedom for Model\n",
        "- $p$ is the number of independent variables\n",
        "\n",
        "Similarly, MSE is calculated as:\n",
        "\n",
        "$$\\text{MSE} = \\frac{\\text{SSE}}{\\text{DFE}}=\\frac{\\sum(y - y_{\\text{pred}})^2}{ N - p}$$\n",
        "\n",
        "where,\n",
        "- SSE is the Sum of Squares for Errors\n",
        "- DFE is Degrees of Freedom for Errors\n",
        "- $N$ is number of instances (or rows) in the dataset\n",
        "\n",
        "Let's create `mean_sq_model()` and `mean_sq_error()` functions to calculate the MSM and MSE values using the above formulae respectively.\n",
        "\n",
        "**Note:** You can also obtain the MSM and MSE values using the `mse_model` and `mse_resid` attributes respectively of `statsmodels.api` module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k87IbgJ2o-Br"
      },
      "source": [
        "# S2.1: Calculate N and p values\n",
        "N ,p = X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nB_mnlQfq4HM"
      },
      "source": [
        "# S2.2: Create functions to calculate MSM and MSE values respectively.\n",
        "Y_train_pre = lin_reg.predict(X_train_sm)\n",
        "Y_test_pre = lin_reg.predict(sm.add_constant(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kljuui_SrREE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5be4d2f-a2f3-4cc4-a80d-3bc03c002a56"
      },
      "source": [
        "# S2.3: Calculate the MSM and MSE on the train sets\n",
        "def msm():\n",
        "  msm_1  = ((Y_train_pre - y_train.mean())**2).sum()\n",
        "  msm  = msm_1/(p-1)\n",
        "  return msm\n",
        "msm()\n",
        "def mse():\n",
        "  mse_1 = ((y_train - Y_train_pre)**2).sum()\n",
        "  mse  = mse_1/(N - p)\n",
        "  return mse\n",
        "mse()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2375608.36022141"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeXUsj5Ds9LN"
      },
      "source": [
        "Now let us calculate the F-statistic value using the\n",
        "\n",
        "$$F* = \\frac{\\text{MSM}}{\\text{MSE}}$$\n",
        "\n",
        " formula."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP6rtlBEtS_A"
      },
      "source": [
        "# S2.4: Calculate the F-statistic using the above formula.\n",
        "a = msm()\n",
        "b = mse()\n",
        "f_sta = a/b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF35-Ib0ux0R"
      },
      "source": [
        "**Step 3: Determine the p-value or probability value for the F-statistic**\n",
        "\n",
        "We can use manually calculate p-value for any test-statistic using the formula:\n",
        "$$\\textrm{p value} = 2 \\times  (1 - \\textrm{cdf}(|ts|))$$\n",
        "\n",
        "where $|ts|$ is the absolute value of test statistic (in this case, F-statistic)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KUSyTPlvNrQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b79cf985-00fc-4b6f-9d44-ce4ef0fa25fd"
      },
      "source": [
        "# S2.5: Calculate p-value for F-statistic.\n",
        "from scipy.stats import norm\n",
        "p_value = 2*( 1- norm.cdf(np.abs(f_sta)))\n",
        "p_value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1tK5Pjpvab-"
      },
      "source": [
        "We can also directly calculate p-value for F-statistic using `f_pvalue` attribute of the `statsmodels.api` module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqP5GjemvZ__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dca42a8-3e8a-4089-f7ff-893957b65830"
      },
      "source": [
        "# S2.6: Calculate p-value using f_pvalue attribute\n",
        "lin_reg.f_pvalue"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.515694157936495e-53"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPpkhyzvwazi"
      },
      "source": [
        "Thus, the F-statistic value is 61.81 and its p-value is 0.0. You may observe a slight difference in the `F-statistic` and `Prob (F-statistic)` values of the summary table as it works slightly different. This is to show that you can also derive F-statistic and its p-value directly from the summary table.\n",
        "\n",
        "**Step 4: Accept or reject null hypothesis based on the p-value**\n",
        "\n",
        "After determining the p-value, we either accept or reject our null hypothesis.\n",
        "\n",
        "If p-value is below 0.05, the null hypothesis will be rejected. Let's determine whether the p-value is below 0.05 or not.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kC7V6ex4V6U"
      },
      "source": [
        "# S2.7: Create a function to accept or reject null hypothesis\n",
        "def null_hypothesis(p):\n",
        "  if p < 0.05:\n",
        "    print('rejecting null hypothesis,significant ')\n",
        "  else :\n",
        "    print('it is not significant ,accepting hypothesis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_hypothesis(p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2nuIZJHFv6b",
        "outputId": "35b119cb-68ce-46f0-e6d6-79ec213090d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rejecting null hypothesis,significant \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rex_Dpqw4iFx"
      },
      "source": [
        "The p-value that we obtained from F-test is equal to 0.00, so we can reject our null hypothesis and conclude that at least one of the independent variable has linear relationship with our target variable `price`. But, what is p-value?\n",
        "\n",
        "**What is meant by p-value?**\n",
        "\n",
        "The p-value is a probability value that helps us to determine whether our hypothesis is correct. The p-value for each feature tests the null hypothesis that there is no correlation between the feature and the target variable. Smaller the p-value, stronger is the evidence that you should reject null hypothesis. A p-value less than 0.05 is statistically significant. It indicates that there is less than 5% probability that the null hypothesis is correct. Therefore, we reject the null hypothesis, and accept the alternative hypothesis. However, a p-value greater than 0.05 indicates weak evidence and we fail to reject the null hypothesis.\n",
        "\n",
        "The F-test for our model rejected the null hypothesis and concluded that at least one feature variable is significant and our model definitely possess predictive capability. Now, we will perform **t-test** to determine which variables are significant in predicting the price of a car and which are not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRB8dcxb5lsA"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCeaSQ-n7NXJ"
      },
      "source": [
        "#### Activity 3: T-Test\n",
        "\n",
        "After concluding from the F-test that at least one feature variable is significant, now we may want to know which variables are significant. For this, we can do a **t-test** to find out which independent variable is making a useful contribution in the prediction of the dependent variable.\n",
        "\n",
        "Remember, the regression equation for our model is:\n",
        "\n",
        "\n",
        "\n",
        "$$Y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3 + \\dots + \\beta_{59} x_{59} + \\epsilon$$\n",
        "\n",
        "where,\n",
        " - $x_1$ is `symboling`\n",
        " - $x_2$ is `doornumber`\n",
        " - $x_3$ is `wheelbase`\n",
        "\n",
        " $\\vdots$   \n",
        "\n",
        " - $x_{59}$ is `wheelbase` and\n",
        " - $Y$ is the `price`\n",
        "\n",
        "For example, let us determine whether feature `symboling` is contributing significantly in the prediction of dependent variable `price`. We will follow the same steps as that of F-test.\n",
        "\n",
        "**Step 1:  Define the null and alternative hypothesis**\n",
        "\n",
        "$H_0:   \\beta_1 = 0$ i.e. `symboling` and `price` are not linearly related\n",
        "\n",
        "$H_1:   \\beta_1 \\neq 0$ i.e. `symboling` and `price` are linearly related\n",
        "\n",
        "**Step 2: Calculate the test statistic value** (in case of t-test, it is t-statistic value)\n",
        "\n",
        "The t-statistic is calculated as:\n",
        "\n",
        "$$t∗= \\frac{\\textrm{coefficient - hypothesized  value} }{\\textrm{standard  error  of  coefficient}}$$\n",
        "\n",
        "As the hypothesized value is usually 0,\n",
        "$$t∗= \\frac{\\textrm{coefficient} }{\\textrm{standard  error  of  coefficient}}$$\n",
        "\n",
        "For our example above, the t-statistic is:\n",
        "\n",
        "$$t∗= \\frac{\\beta_1 }{SE(\\beta_1)}$$\n",
        "\n",
        "The **standard error of coefficient (SE)** is an estimate of the standard deviation of the coefficient, the amount it varies across cases. Its formula is quite complicated.\n",
        "\n",
        "However, we can obtain standard error for every coefficient by using `bse` attribute of `statsmodels.api` module. The `b` in `bse` stands for the coefficient $\\beta$ and `se` for standard errors.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W74Uh6Oa82C7"
      },
      "source": [
        "# T3.1: Calculate the SE(beta_1) value.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fB6j9d094l8"
      },
      "source": [
        "# T3.2: Calculate t-statistic for beta_1 using the above formula.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXwNEAyT-X0K"
      },
      "source": [
        "**Step 3:  Determine the p-value or probability value for the t-statistic**\n",
        "\n",
        "After obtaining the t-statistic for $\\beta_1$, let's validate the null hypothesis by calculating the p-value.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtTAnmdm-fJP"
      },
      "source": [
        "# T3.3: Calculate p-value based on t-statistic.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-bMn1aa-1cG"
      },
      "source": [
        "Thus the t-statistic value for $\\beta_1$ is -0.766 and its p-value is 0.443. You can also derive these values directly from the summary table.\n",
        "\n",
        "**STEP 4: Accept or reject null hypothesis based on the p-value**\n",
        "\n",
        "After determining the p-value, we either accept or reject our null hypothesis.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx8Bm83l_HpY"
      },
      "source": [
        "# S3.1: Accept or reject null hypothesis\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoEIHQEc_d7M"
      },
      "source": [
        "Since the p-value is above 0.05, the null hypothesis will be accepted. This means that `symboling` and `price` are not linearly related and `symboling` is not making a useful contribution in predicting the target variable `price`. Hence, we can remove this feature from our model.\n",
        "\n",
        "Similarly, let's perform t-test for the second feature `doornumber` to determine whether it is significant or not. For this, our null hypothesis and alternate hypothesis would be:\n",
        "\n",
        "$H_0:   \\beta_2 = 0$ i.e. `doornumber` and `price` are not linearly related\n",
        "\n",
        "$H_1:   \\beta_2 \\neq 0$ i.e. `doornumber` and `price` are  linearly related\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9Nf7rJTAlI2"
      },
      "source": [
        "# S3.2: Calculate the SE(beta_2) value.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJdf1NrCAtaB"
      },
      "source": [
        "# S3.3: Calculate t-statistic for beta_2 using formula\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl1Nx1f9A6L-"
      },
      "source": [
        "# S3.4: Calculate p-value based on t-statistic\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14smmrFRCEzJ"
      },
      "source": [
        "# S3.5: Accept or reject null hypothesis\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqNFRfH3CLPu"
      },
      "source": [
        "Since the p-value is above 0.05, the null hypothesis will be accepted. This means that the feature `doornumber` is not making a useful contribution in predicting the target variable `price`. Hence, we can remove this feature from our model.\n",
        "\n",
        "Similarly, you can perform t-test for each independent variable and determine which variable is actually contributing in predicting the price of a car.\n",
        "\n",
        "You can obtain p-values for all features all at once either from the summary of linear regression report or by using `pvalues` attribute of Linear regression object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuTVDydcDhB9"
      },
      "source": [
        "# S3.6: Obtain p-values for all features\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrL_v5-lDvcz"
      },
      "source": [
        "Let us obtain those features whose p-value is less than 0.05 and perform linear regression using the reduced features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1viwlEMcQIIc"
      },
      "source": [
        "# S3.7: Create a dataframe with Features and their corresponding p-values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnllksChTeQS"
      },
      "source": [
        "# S3.8: Drop those features whose p-value is greater than 0.05\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grmZkV4dTozs"
      },
      "source": [
        "As you can see, we created a dataframe with only significant features. Now let us again perform linear regression using the reduced features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wi-4VYmEUOV8"
      },
      "source": [
        "# S3.9: Build a linear regression model again with reduced features\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_5R_5YUXffV"
      },
      "source": [
        "# S3.10: Print the summary table for the above linear regression model.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64zwtdo2PBb0"
      },
      "source": [
        "We build the linear regression model again after removing all the features having the higher p-value and we still have a few features which have high p-values. This is not the right approach to tackle the high-values issue. Ideally, in the first iteration, we should remove only one feature having higher p-value, then rebuild the model, then again check for the p-value and then remove the next feature having highest p-value and so on.\n",
        "\n",
        "These iterations can become very long. We can reduce the number of iterations by finding out the most relevant features in the first go. In the next class, we will how to select such relevant features to reduce the number of iterations for building the most accurate linear regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijKY83ukqRon"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n41zL-OCskHC"
      },
      "source": [
        "### **Project**\n",
        "You can now attempt the **Applied Tech Project 69 - Car price prediction - Interpreting p-values** on your own.\n",
        "\n",
        "**Applied Tech Project 69 - Car price prediction - Interpreting p-values**: https://colab.research.google.com/drive/1fkUA8fMoDcZnia1kOeDgP0KnOoRUoU_6?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6YLADRwsyDk"
      },
      "source": [
        "---"
      ]
    }
  ]
}